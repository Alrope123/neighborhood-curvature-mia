{
    "dataset_member": "wikipedia",
    "dataset_member_key": "text",
    "dataset_nonmember": "wikipedia",
    "dataset_nonmember_key": "text",
    "pct_words_masked": 0.3,
    "span_length": 2,
    "n_samples": 5000,
    "n_perturbation_list": "1,10",
    "n_perturbation_rounds": 1,
    "base_model_name": "EleutherAI/gpt-neo-2.7B",
    "revision": "main",
    "scoring_model_name": "",
    "mask_filling_model_name": "t5-large",
    "batch_size": 50,
    "chunk_size": 20,
    "n_similarity_samples": 20,
    "int8": false,
    "half": false,
    "base_half": false,
    "do_top_k": false,
    "top_k": 40,
    "do_top_p": false,
    "top_p": 0.96,
    "output_name": "unified_mia",
    "openai_model": null,
    "openai_key": null,
    "baselines_only": true,
    "skip_baselines": false,
    "buffer_size": 1,
    "mask_top_p": 1.0,
    "pre_perturb_pct": 0.0,
    "pre_perturb_span_length": 5,
    "random_fills": false,
    "random_fills_tokens": false,
    "cache_dir": "cache",
    "ref_model": "gpt2-xl",
    "tok_by_tok": false,
    "max_tries": 100,
    "max_length": 2000,
    "ceil_pct": false
}